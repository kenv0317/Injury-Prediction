{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOW6zRT5riBprgaxYatg4jX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "v4_mgijObz_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uploading 2015-2022 database\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "pitch_data_all = pd.read_csv('pitch_data_2015_2022 - pitch_data_2015_2022.csv')"
      ],
      "metadata": {
        "id": "-aj8FO2lcF_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uploading 2023 database\n",
        "\n",
        "uploaded = files.upload()\n",
        "pitch_data_2023 = pd.read_csv('pitch_data_2023 - pitch_data_2023.csv')"
      ],
      "metadata": {
        "id": "uezHiy_4cJZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoOtL-jtbaeQ"
      },
      "outputs": [],
      "source": [
        "# 訓練データ\n",
        "# 全特徴量\n",
        "#x_train = pitch_data_all.drop(['Name','Lev','Tm','Injury','Year'], axis=1)\n",
        "\n",
        "# Filter法で選択した特徴量\n",
        "#x_train = pitch_data_all[['SO', 'W', 'IP', 'Pit', 'AB', 'SO/W', 'BF', 'BB', 'H', 'GS', 'GDP', 'R', '2B', 'ER', 'L', 'HR', 'G', 'SB', 'SO9', 'StS', 'CS', '3B', 'HBP', 'Arm', 'Shoulder', 'Str', 'SF', 'PO']]\n",
        "\n",
        "# Wrapper法(Step forward)で選択した特徴量\n",
        "x_train = pitch_data_all[['W', 'Shoulder', 'Arm', 'Elbow', 'Ribs', 'Oblique', 'Finger', 'Ankle', 'Hip', 'Achilles', 'Wrist', 'Calf', 'Hand', 'Leg', 'Shin']]\n",
        "\n",
        "# Wrapper法(Back forward)で選択した特徴量\n",
        "#x_train = pitch_data_all[]\n",
        "\n",
        "y_train = pitch_data_all['Injury']\n",
        "\n",
        "# 検証データ\n",
        "# 全特徴量\n",
        "#x_test = pitch_data_2023.drop(['Name','Lev','Tm','Injury','Year'], axis=1)\n",
        "\n",
        "# Filter法で選択した特徴量\n",
        "#x_test = pitch_data_2023[['SO', 'W', 'IP', 'Pit', 'AB', 'SO/W', 'BF', 'BB', 'H', 'GS', 'GDP', 'R', '2B', 'ER', 'L', 'HR', 'G', 'SB', 'SO9', 'StS', 'CS', '3B', 'HBP', 'Arm', 'Shoulder', 'Str', 'SF', 'PO']]\n",
        "\n",
        "# Wrapper法で選択した特徴量\n",
        "x_test = pitch_data_2023[['W', 'Shoulder', 'Arm', 'Elbow', 'Ribs', 'Oblique', 'Finger', 'Ankle','Hip', 'Achilles', 'Wrist', 'Calf', 'Hand', 'Leg', 'Shin']]\n",
        "\n",
        "# Wrapper法(Back forward)で選択した特徴量\n",
        "#x_test = pitch_data_2023[]\n",
        "\n",
        "y_test = pitch_data_2023['Injury']\n",
        "\n",
        "\n",
        "# ロジスティック回帰で学習する\n",
        "model1 = LogisticRegression()\n",
        "model1.fit(x_train, y_train)\n",
        "\n",
        "# ランダムフォレスト\n",
        "model2 = RandomForestClassifier()\n",
        "model2.fit(x_train, y_train)\n",
        "\n",
        "# k近傍探索\n",
        "model3 = KNeighborsClassifier(n_neighbors=4)\n",
        "model3.fit(x_train, y_train)\n",
        "\n",
        "#XGBoost\n",
        "model4 = XGBClassifier(booster=\"gbtree\",             # ブースター種類（ツリーモデル：gbtree or dart, 線形モデル：gblinear)\n",
        "                          learning_rate=1,              # 過学習防止を目的とした学習率\n",
        "                          min_split_loss=0,             # 決定木の葉ノード追加に伴う損失減少の下限値\n",
        "                          max_depth=6,                  # 決定木の深さの最大値\n",
        "                          min_child_weight=1,           # 決定木の葉に必要な重みの下限\n",
        "                          subsample=1,                  # 各決定木においてランダム抽出されるサンプル割合\n",
        "                          sampling_method=\"uniform\",    # サンプリング方法\n",
        "                          colsample_bytree=1,           # 各決定木でランダムに設定される説明変数の割合\n",
        "                          colsample_bylevel=1,          # 決定木が深さ単位で分割される際に利用する説明変数の割合\n",
        "                          reg_lambda=1,                 # L2正則化のペナルティ項\n",
        "                          reg_alpha=0,                  # L1正則化のペナルティ項\n",
        "                          tree_method=\"auto\",           # ツリー構造アルゴリズム\n",
        "                          process_type=\"default\",       # 実行するブースティングプロセス\n",
        "                          grow_policy=\"depthwise\",      # 新しい葉ノードを木に追加する際の制御ポリシー\n",
        "                          max_leaves=0,                 # 追加する葉ノードの最大数\n",
        "                          objective=\"reg:squarederror\", # 学習プロセスで最小化を目指す損失関数\n",
        "                          num_round=9,                  # ブースティング回数(=作成する決定木の本数)\n",
        "                         )\n",
        "\n",
        "\n",
        "# モデル学習\n",
        "model4.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 予測結果出力\n",
        "y_pred1 = model1.predict(x_test)\n",
        "print('LogisticRegression:', y_pred1[:30])\n",
        "\n",
        "y_pred2 = model2.predict(x_test)\n",
        "print('RandomForest:', y_pred2[:30])\n",
        "\n",
        "y_pred3 = model3.predict(x_test)\n",
        "print('KNeighbors:', y_pred3[:30])\n",
        "\n",
        "y_pred4 = model4.predict(x_test)\n",
        "print('XGBoost:', y_pred4[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY7Bmh3UeDJ5",
        "outputId": "df21adef-b9ad-4e9b-8b18-400a67588341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression: [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0]\n",
            "RandomForest: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
            "KNeighbors: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "XGBoost: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル評価\n",
        "\n",
        "# Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('accuracy_score:')\n",
        "print('LogisticRegression:', accuracy_score(y_test, y_pred1))\n",
        "\n",
        "print('RandomForest:', accuracy_score(y_test, y_pred2))\n",
        "\n",
        "print('KNeighbors:', accuracy_score(y_test, y_pred3))\n",
        "\n",
        "print('XGBoost:', accuracy_score(y_test, y_pred4))\n",
        "\n",
        "# AUC\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print('AUC:')\n",
        "y_pred_prob = model1.predict_proba(x_test)[:,1]\n",
        "print('LogisticRegression:', roc_auc_score(y_test, y_pred_prob))\n",
        "\n",
        "y_pred_prob = model2.predict_proba(x_test)[:,1]\n",
        "print('RandomForest:', roc_auc_score(y_test, y_pred_prob))\n",
        "\n",
        "y_pred_prob = model3.predict_proba(x_test)[:,1]\n",
        "print('KNeighbors:', roc_auc_score(y_test, y_pred_prob))\n",
        "\n",
        "y_pred_prob = model4.predict_proba(x_test)[:,1]\n",
        "print('XGBoost:', roc_auc_score(y_test, y_pred_prob))\n",
        "\n",
        "# F score\n",
        "from sklearn.metrics import f1_score\n",
        "print('F score:')\n",
        "print('LogisticRegression:', f1_score(y_test, y_pred1))\n",
        "\n",
        "print('RandomForest:', f1_score(y_test, y_pred2))\n",
        "\n",
        "print('KNeighbors:', f1_score(y_test, y_pred3))\n",
        "\n",
        "print('XGBoost:', f1_score(y_test, y_pred4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6WiS6aNbylk",
        "outputId": "25d6f0c3-03d6-4ae6-e581-25829d8d45b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score:\n",
            "LogisticRegression: 0.6590126291618829\n",
            "RandomForest: 0.6601607347876005\n",
            "KNeighbors: 0.661308840413318\n",
            "XGBoost: 0.6681974741676234\n",
            "AUC:\n",
            "LogisticRegression: 0.6601463443535964\n",
            "RandomForest: 0.6329985780305724\n",
            "KNeighbors: 0.6093464865505391\n",
            "XGBoost: 0.6138553146107358\n",
            "F score:\n",
            "LogisticRegression: 0.28433734939759037\n",
            "RandomForest: 0.3451327433628319\n",
            "KNeighbors: 0.21333333333333332\n",
            "XGBoost: 0.35634743875278396\n"
          ]
        }
      ]
    }
  ]
}